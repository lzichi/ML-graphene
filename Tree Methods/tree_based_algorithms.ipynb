{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based algorithms\n",
    "\n",
    "Use the information from parameter creation to train and test tree-based algorithms against data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas.core.indexing import convert_missing_indexer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, classification_report, roc_curve, roc_auc_score)\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from scipy.special import expit\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Settings\n",
    "%matplotlib inline\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.ROOT)\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'xaxis.labellocation': 'center', \n",
    "         'yaxis.labellocation': 'center'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoroithm training / running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, labels, target, train_portion=0.75, seed=1):\n",
    "    #t0 = time()\n",
    "    np.random.seed(seed)\n",
    "    assert 'names' in data.columns, f'`names` column is not found in df.'\n",
    "\n",
    "    full_data = data.copy()\n",
    "    full_data['original_name'] = full_data.names.apply(lambda x: '_'.join(x.split('_')[int('aug' in x or 'raw' in x) + int('aug' in x):]))\n",
    "    original_imgs = np.unique(full_data['original_name'])\n",
    "    train_img = set(np.random.choice(original_imgs, \n",
    "                                 int(train_portion * len(original_imgs)),\n",
    "                                 False))\n",
    "    train_idx = full_data.original_name.apply(lambda x: x in train_img)\n",
    "    train_data = full_data[train_idx].drop('original_name', 1)\n",
    "    test_data = full_data[~train_idx].drop('original_name', 1)\n",
    "    \n",
    "    X_train = train_data[labels]\n",
    "    X_test = test_data[labels]\n",
    "    \n",
    "    y_train = train_data[target]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "\n",
    "    X_train=X_train.astype('int')\n",
    "    X_test=X_test.astype('int')\n",
    "    \n",
    "    #print(time() - t0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_subset(data, labels, target, test_portion=0.25, train_subset_portion=1., seed=1):\n",
    "    \"\"\"\n",
    "    This function creates train and test data.\n",
    "    The test data is fixed to test_portion * len(data) .\n",
    "    The train data contains (1 - test_portion) * train_subset_portion.\n",
    "    (1 - test_portion) * (1 - train_subset_portion) samples will be discarded. \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    assert 'names' in data.columns, f'`names` column is not found in df.'\n",
    "\n",
    "    full_data = data.copy()\n",
    "    full_data['original_name'] = full_data.names.apply(\n",
    "        lambda x: '_'.join(x.split('_')[int('aug' in x or 'raw' in x) + int('aug' in x):]))\n",
    "    original_imgs = np.unique(full_data['original_name'])\n",
    "    assert original_imgs.shape[0] == 332\n",
    "    train_img = set(np.random.choice(original_imgs, \n",
    "                                 int((1-test_portion) * len(original_imgs)),\n",
    "                                 False))\n",
    "    train_idx = full_data.original_name.apply(lambda x: x in train_img)\n",
    "    train_data = full_data[train_idx]\n",
    "    test_data = full_data[~train_idx]\n",
    "\n",
    "    if train_subset_portion < 1:\n",
    "        # Use a subset to train the model.\n",
    "        train_imgs = np.unique(train_data['original_name'])\n",
    "        train_subimg = set(np.random.choice(train_imgs, \n",
    "                                    int(train_subset_portion * len(train_imgs)),\n",
    "                                    False))\n",
    "        train_subidx = train_data.original_name.apply(lambda x: x in train_subimg)\n",
    "        train_data = train_data[train_subidx]\n",
    "    \n",
    "    train_data = train_data.drop('original_name', 1).reset_index()\n",
    "    test_data = test_data.drop('original_name', 1).reset_index()\n",
    "    \n",
    "    X_train = train_data[labels]\n",
    "    X_test = test_data[labels]\n",
    "    \n",
    "    y_train = train_data[target]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "\n",
    "    X_train=X_train.astype('int')\n",
    "    X_test=X_test.astype('int')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(X_train, X_test, y_train, y_test, labels, target, df_run, print_all, plot_DT, plot_RF):\n",
    "    '''Take in a set of train test split data and run a \n",
    "       decision tree, knn, boosted decision tree and, random forest,'''\n",
    "    t0 = time()\n",
    "    # Decision tree\n",
    "    max = 7\n",
    "    max_leaf = 10\n",
    "    decision_tree_clf = DecisionTreeClassifier(max_depth = max, \n",
    "                                               random_state=0, max_leaf_nodes = max_leaf).fit(X_train, y_train)\n",
    "    #decision_tree_clf = DecisionTreeClassifier( max_leaf_nodes = 10).fit(X_train, y_train)\n",
    "    #decision_tree_clf = DecisionTreeClassifier(max_depth = 5, random_state=0).fit(X_train, y_train)\n",
    "    \n",
    "    print('Decison Tree:', time() - t0)\n",
    "    \n",
    "    # Boosted decision trees\n",
    "    t0 = time()\n",
    "    l_r = 0.002\n",
    "    m_d = 5\n",
    "    BDT_clf = GradientBoostingClassifier(learning_rate=l_r, max_depth=m_d,\n",
    "                                      random_state=0).fit(X_train, y_train)\n",
    "    print('BDT', time() - t0)\n",
    "\n",
    "    # Random Forest\n",
    "    t0 = time()\n",
    "    max_d = 5\n",
    "    n_estimators = 4\n",
    "    min_leaf= 1\n",
    "    \n",
    "    RF_clf = RandomForestClassifier(max_depth = max_d, n_estimators = n_estimators, random_state = 0).fit(X_train, y_train)\n",
    "    #RF_clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "    print('RF', time() - t0)\n",
    "\n",
    "    if print_all:\n",
    "        \n",
    "        print('Decision Tree, max_depth={}, max_leaf_nodes={}'.format(max, max_leaf))\n",
    "        print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "             .format(decision_tree_clf.score(X_train, y_train)))\n",
    "        print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "             .format(decision_tree_clf.score(X_test, y_test)))\n",
    "        print()\n",
    "        print('GBDT, learning_rate={}, max_depth={}'.format(l_r, m_d))\n",
    "        print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "             .format(BDT_clf.score(X_train, y_train)))\n",
    "        print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "             .format(BDT_clf.score(X_test, y_test)))\n",
    "        print()\n",
    "        print('Random Forest, (max depth = {}, n_estimators = {})'.format(max_d, n_estimators))\n",
    "        print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "             .format(RF_clf.score(X_train, y_train)))\n",
    "        print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "             .format(RF_clf.score(X_test, y_test)))\n",
    "\n",
    "    if plot_DT:\n",
    "       # Plot decision tree\n",
    "        fn= (labels)\n",
    "        cn = ['no flake', 'flake']\n",
    "        #cn = str(df_run['target'])\n",
    "        #fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "        #tree.plot_tree(decision_tree_clf,\n",
    "                    #   feature_names = fn, \n",
    "                    #   class_names=cn,\n",
    "                    #   filled = True, label = 'none');\n",
    "        #fig.savefig('decisiontree.png')\n",
    "        \n",
    "        dot_data = tree.export_graphviz(decision_tree_clf, out_file=None, \n",
    "                                feature_names=fn,  \n",
    "                                class_names=None,\n",
    "                                filled=True, impurity = True, rounded = True)\n",
    "        graph = graphviz.Source(dot_data, format=\"png\") \n",
    "        graph.render(\"decision_tree_graphivz.png\")\n",
    "        \n",
    "    if plot_RF:\n",
    "        # Extract single tree\n",
    "        estimator = RF_clf.estimators_[-1]\n",
    "        fn= (labels)\n",
    "        cn = str(df_run[target])\n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "        tree.plot_tree(estimator,\n",
    "                       feature_names = fn, \n",
    "                       class_names=cn,\n",
    "                       filled = True);\n",
    "        fig.savefig('RF.png')\n",
    "\n",
    "        \n",
    "    return decision_tree_clf, BDT_clf, RF_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of algorihtms \n",
    "\n",
    "Use cross validation to determine best hyperparameters for the algorithm. Display result with ROC curve, confusion matrix, and visualization of decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid(clf, param_grid, scoring, X_train, y_train, X_test, y_test, cv_in = 10):\n",
    "    t0 = time()\n",
    "    '''Take a classifier and find best parameters'''    \n",
    "    grid = GridSearchCV(clf, param_grid = param_grid, cv = cv_in)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # print prediction results \n",
    "    y_true, y_pred = y_test, grid.predict(X_test)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    acc = report['accuracy']\n",
    "\n",
    "    results = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "  \n",
    "    # Find average\n",
    "    aves = results['mean_test_score']\n",
    "    ave = aves.max()\n",
    "    ave_index = aves.idxmax()\n",
    "\n",
    "    # Find the minimum, min, std based on highest average \n",
    "    #ser2 = results.loc[max_index]\n",
    "    ser2 = results.loc[ave_index]\n",
    "    arr = ser2.to_numpy()\n",
    "    min = arr[7:12].min()\n",
    "    max = arr[7:12].max()\n",
    "    std = results.iloc[results['mean_test_score'].idxmax()]['std_test_score']\n",
    "\n",
    "    return max, min, ave, acc, std, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(clfs, X_test, y_test, title, names):\n",
    "    '''Plot confusion matrix for a given classifier and test results'''\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize = (25, 6))\n",
    "\n",
    "    for clf, name, ax in zip (clfs, names, axs):\n",
    "        plot_confusion_matrix(clf, X_test, y_test, ax=ax, display_labels=np.array(['Flake','No Flake']),\n",
    "                                    cmap=plt.cm.YlGnBu, colorbar = False)\n",
    "    ax.set_title(\"%s %s\"%(name, title), fontsize = 20)\n",
    "    plt.show()\n",
    "    fig.savefig(\"%s %s\"%(name, title), facecolor= 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve(clfs, names, df, title):\n",
    "    ''' Plot confusion matrix for a given classifier'''\n",
    "  \n",
    "    ## ROC Curve ##\n",
    "    target = 'labels'\n",
    "    labels = [df.columns[4],'[ 5. 10.]', '[10. 20.]','[20. 30.]','[30. 40.]','[40. 50.]','[50. 60.]','[60. 70.]','[70. 80.]','[80. 90.]','[ 90. 100.]','[100. 110.]','[110. 120.]','[120. 130.]','[130. 140.]','[140. 180.]', df.columns[3+16]]\n",
    "\n",
    "    X = df[labels]\n",
    "    y = df[target] \n",
    "    y=y.astype('int')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "    colors = ['#2c7fb8', '#7fcdbb', '#bebada']\n",
    "    for clf, name, col in zip (clfs, names, colors):\n",
    "        # fit model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # predict probabilities\n",
    "        pred_prob1 = clf.predict_proba(X_test)\n",
    "\n",
    "        # roc curve for models\n",
    "        fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "\n",
    "        # roc curve for tpr = fpr \n",
    "        random_probs = [0 for i in range(len(y_test))]\n",
    "        p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "        # auc scores\n",
    "        auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\n",
    "\n",
    "        # plot roc curves\n",
    "        plt.plot(fpr1, tpr1, linestyle='--',color=col, label=\"%s (area = %0.2f)\" % (name, auc_score1))\n",
    "\n",
    "    # title\n",
    "    #plt.title(\"ROC Curve %s\"%(title))\n",
    "    # x label\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    # y label\n",
    "    plt.ylabel('True Positive rate')\n",
    "\n",
    "    plt.legend(loc='best', fontsize = 20)\n",
    "    plt.savefig(\"ROC_CURVE_%s %s\"%(name, title), facecolor= 'white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(x, percent, cnn, dt, bdt, rf):\n",
    "    ''' Creates four panel figure of accuracies for each classifier (cnn, decision\n",
    "        tree, random forest, graident boosted tree). Line for average test and \n",
    "        accuracy on test with std as error bars.'''\n",
    "    \n",
    "    kfold_arrs = np.array([dt, bdt, rf])\n",
    "    legends = np.array(['Decision Tree', 'Gradient Boosted', 'Random Forest'])\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, sharey=True, figsize=(15, 10))\n",
    "    axs[0].plot(x, cnn, '-o', color = '#225ea8')\n",
    "    axs[0].set_title('CNN', fontsize = 24)\n",
    "    axs[0].set_xscale('log')\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "\n",
    "    for kfold_arr, leng, ax, acc in zip (kfold_arrs, legends, axs[1:], accs):\n",
    "        kfold_arr = np.array(kfold_arr)\n",
    "        y = kfold_arr[:,2]\n",
    "\n",
    "        ax.fill_between(x, kfold_arr[:,2] + kfold_arr[:,3], kfold_arr[:,2] - kfold_arr[:,3], color = '#edf8b1', hatch = '/',\n",
    "                  alpha=0.5)\n",
    "        ax.set_title(leng, fontsize = 24)\n",
    "        ax.plot(x, y, '-o', color = '#225ea8')\n",
    "        ax.plot(x, kfold_arr[:,4], '-o', color = '#7fcdbb')\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "\n",
    "    axs[0].set_ylabel('Accuracy of Classifier')\n",
    "    #text = ('Accuracies with %s %s Training Data'%(percent, '%'))\n",
    "    #axs[1].text(0.1, np.max(kfold_arrs[2][:,2] + kfold_arrs[2][:,3])*1.01\n",
    "             # , text, fontsize = 22)\n",
    "    axs[2].set_xlabel('Number of Quantized Colors')\n",
    "    #axs[2].xaxis.set_label_coords(0, .50)\n",
    "    plt.savefig('Accuracy_plot_%s.png'%(percent))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_cv(dfs, titles, scoring_in = 'accuracy', cv_in = 10, trainPortion = 1, cnn = [], isConfusion_ROC = True, isDisplayTree = True, isPlotAccuracy = True, x = [5, 20, 256]):\n",
    "    count = 0\n",
    "    rf_n = []\n",
    "    dt_n = []\n",
    "    bdt_n = []\n",
    "\n",
    "    #titles = ['Five Colors', 'Ten Colors', '15 Colors', '20 Colors', '20 Colors']\n",
    "    for df, title in zip (dfs, titles):\n",
    "\n",
    "        target = 'labels'\n",
    "        labels = [df.columns[4],'[ 5. 10.]', '[10. 20.]','[20. 30.]','[30. 40.]','[40. 50.]','[50. 60.]','[60. 70.]','[70. 80.]','[80. 90.]','[ 90. 100.]','[100. 110.]','[110. 120.]','[120. 130.]','[130. 140.]','[140. 180.]', df.columns[3+16]]\n",
    "\n",
    "        ## Run Machine learning ##\n",
    "        X_train, X_test, y_train, y_test = train_test_split_tin(df, labels, target)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split_subset(df, labels, target, test_portion=0.25, train_subset_portion=trainPortion)\n",
    "\n",
    "        # Decision Tree\n",
    "        param_dict = { \"max_depth\":range(4,8), 'max_leaf_nodes':range(5, 20)} \n",
    "        max, min, ave, acc, std, dt_clf = grid_search(DecisionTreeClassifier(), param_dict, \"accuracy\", X_train, y_train, X_test, y_test, cv_in = cv_in)\n",
    "        dt_n.append(np.array([max, min, ave, std, acc]))\n",
    "        print('average: ', ave, ' accuracy: ', acc, 'min: ', min, 'max: ', max)\n",
    "\n",
    "        # Random Forests\n",
    "        param_dict = { \"max_depth\":range(4,10), \"n_estimators\":range(1,10)} \n",
    "        max, min, ave, acc, std, rf_clf = grid_search(RandomForestClassifier(), param_dict, \"accuracy\", X_train, y_train, X_test, y_test, cv_in = cv_in)\n",
    "        rf_n.append(np.array([max, min, ave, std, acc]))\n",
    "        print('average: ', ave, ' accuracy: ', acc, 'min: ', min, 'max: ', max)\n",
    "\n",
    "        # Gradient Boosted Decision Tree \n",
    "        ler = np.array([0.0001, 0.001, 0.01, 0.1, 0.3])\n",
    "        param_dict = {\"learning_rate\":ler, \"max_depth\":range(4,7)} \n",
    "        max, min, ave, acc, std, gbt_clf = grid_search(GradientBoostingClassifier(), param_dict, \"accuracy\", X_train, y_train, X_test, y_test, cv_in = cv_in)\n",
    "        bdt_n.append(np.array([max, min, ave, std, acc]))\n",
    "        print('average: ', ave, ' accuracy: ', acc, 'min: ', min, 'max: ', max)\n",
    "\n",
    "        count = count + 1\n",
    "        print('count: ', count, 'still working ....')\n",
    "\n",
    "        if(isConfusion_ROC):\n",
    "            clfs = [dt_clf, rf_clf, gbt_clf]\n",
    "            names = [\"Decision Tree\", \"Random Forest\", 'Gradient Boosted']\n",
    "            plot_confusion(clfs, X_test, y_test, title, names)\n",
    "            ROC_curve(clfs, names, df, title)\n",
    "\n",
    "        if(isDisplayTree):\n",
    "            fn= (labels)\n",
    "            dot_data = tree.export_graphviz(dt_clf, out_file=None, \n",
    "                                    feature_names=fn,  \n",
    "                                    class_names=None,\n",
    "                                    filled=True, impurity = True, rounded = True)\n",
    "            graph = graphviz.Source(dot_data, format=\"png\") \n",
    "            graph.render(\"decision_tree_graphivz_%s\"%(title))\n",
    "\n",
    "    if(isPlotAccuracy):\n",
    "        plot_accuracy(x, trainPortion, cnn, dt_n, bdt_n, rf_n)\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_classifieres(X_train, X_test, y_train, y_test):\n",
    "    '''Run dummy classifieres for evaluation'''\n",
    "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "    print('Score of Dummy Classifier: ', dummy_majority.score(X_test, y_test))\n",
    "    \n",
    "    dummy_uniform = DummyClassifier(strategy = 'uniform').fit(X_train, y_train)\n",
    "    y_dummy_predictions = dummy_uniform.predict(X_test)\n",
    "    print('Score of Dummy Classifier (uniform): ', dummy_uniform.score(X_test, y_test))\n",
    "    \n",
    "    return dummy_majority, dummy_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_classified(clf, X_test, df_in):\n",
    "    '''Take in a classifier and it's X_test and return four arrays of paths corresponding to TP, TN, FP & FN'''\n",
    "    \n",
    "    clf_predicted = clf.predict(X_test)\n",
    "\n",
    "    X_test2 = X_test.copy()\n",
    "\n",
    "    X_test2['predicted label'] = clf_predicted\n",
    "\n",
    "\n",
    "    indexs = X_test2.index.values\n",
    "\n",
    "    path_arr = []\n",
    "    label_p = []\n",
    "    label_t = []\n",
    "\n",
    "    for index, label in zip (indexs, clf_predicted):\n",
    "        path_arr.append(df_in['paths'][index])\n",
    "        label_t.append(df_in['labels'][index])\n",
    "        label_p.append(label)\n",
    "        \n",
    "    data = {'path': path_arr,\n",
    "            'True label': label_t,\n",
    "            'Predicted label': label_p}\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data) \n",
    "    \n",
    "    word = []\n",
    "    \n",
    "    for i, j in df.iterrows(): \n",
    "        true = j['True label']\n",
    "        predicted = j['Predicted label']\n",
    "\n",
    "        if( (true == 0) & (predicted == 0)):\n",
    "            word.append('TN')\n",
    "\n",
    "        if( (true == 1) & (predicted == 1)):\n",
    "            word.append('TP')\n",
    "\n",
    "        if( (true == 1) & (predicted == 0)):\n",
    "            word.append('FN')\n",
    "\n",
    "        if( (true == 0) & (predicted == 1)):\n",
    "            word.append('FP')\n",
    "\n",
    "    df['Outcome'] = word\n",
    "    TP = df[df['Outcome']== 'TP'].path.values\n",
    "    TN = df[df['Outcome']== 'TN'].path.values\n",
    "    FP = df[df['Outcome']== 'FP'].path.values\n",
    "    FN = df[df['Outcome']== 'FN'].path.values\n",
    "    \n",
    "    return TP, TN, FP, FN, df\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
